{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# A Perceptron in Just a Few Lines of Python Code\n",
    "\n",
    "The perceptron can be used for supervised learning. It can solve binary linear classification problems. A comprehensive description of the functionality of a perceptron is out of scope here. To get in touch with the theoretical background, I advise the Wikipedia article:\n",
    "    \n",
    "[Wikipedia - Perceptron](https://en.wikipedia.org/wiki/Perceptron)\n",
    "\n",
    "To better understand the internal processes of a perceptron, we will step by step develop a perceptron from scratch.\n",
    "\n",
    "To follow this tutorial you already should know what a perceptron is and understand the basics of its functionality. Additionally a fundamental understanding of stochastic gradient descent is needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Give me the code! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  2.  4.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([\n",
    "    [-1,2,-1],\n",
    "    [3,0,-1],\n",
    "    [0,4,-1],\n",
    "    [1,5,-1],\n",
    "    [2,2,-1],\n",
    "])\n",
    "\n",
    "y = np.array([-1,-1,1,1,1])\n",
    "\n",
    "def perceptron_sgd(X, Y):\n",
    "    w = np.zeros(len(X[0]))\n",
    "    eta = 1\n",
    "\n",
    "    for t in range(1000):\n",
    "        for i, x in enumerate(X):\n",
    "            if (np.dot(X[i], w)*Y[i]) <= 0:\n",
    "                w = w + eta*X[i]*Y[i]\n",
    "\n",
    "    return w\n",
    "\n",
    "print(perceptron_sgd(X,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "First we will import numpy to easily manage linear algebraic and calculus operations in python. To plot the learning progress later on, we will use pylab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Our Ingredients \n",
    "\n",
    "### Stochastic Gradient Descent\n",
    "\n",
    "We will implement the perceptron algorithm in python3 and numpy. The perceptron will learn using the stochastic gradient descent algorithm (SGD). For further details see:\n",
    "\n",
    "[Wikipedia - stochastic gradient descent](https://en.wikipedia.org/wiki/Stochastic_gradient_descent)\n",
    "\n",
    "### Calculating The Error \n",
    "\n",
    "To calculate the error of a prediction we first need to define the objective function of the perceptron. \n",
    "\n",
    "#### Hinge Loss Function\n",
    "\n",
    "To do this, we need to define the loss function, to calculate the prediction error. We will use hinge loss for our perceptron:\n",
    "\n",
    "$$c(x, y, f(x)) = (1 - y f(x))_+$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "$c$ is the loss function, $x$ the sample, $y$ is the true label, $f(x)$ the predicted label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "This means the following:\n",
    "$$\n",
    "c(x, y, f(x))= \n",
    "\\begin{cases}\n",
    "    0,& \\text{if } y * f(x)\\geq 1\\\\\n",
    "    1-y*f(x),              & \\text{else}\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "So consider, if y and f(x) are signed values $(+1,-1)$:\n",
    "\n",
    "<ul>\n",
    "    <li>the loss is 0, if $y*f(x)$ are positive, respective both values have the same sign.</li>\n",
    "    <li>loss is $1-y*f(x)$ if $y*f(x)$ is negative</li>\n",
    "</ul>\n",
    "\n",
    "#### Objective Function \n",
    "\n",
    "As we defined the loss function, we can now define the objective function for the perceptron:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$l_i(w) = \\big(-y_i \\langle x_i,w \\rangle\\big)_+$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "We can write this without the dot product with a sum symbol:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$l_i(w) = (-y_i \\sum_{i=1}^n x_iw)_+$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the sample $x_i$ is misclassified, if $−y_i \\langle x_i,w \\rangle \\leq 0$\n",
    "\n",
    "#### Derive The Objective Function\n",
    "\n",
    "To use this objective function in the SGD algorithm, we need to partially derivate it.\n",
    "\n",
    "$$ \\nabla l_i(w) = -y_i x_i $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "\n",
    "This means, if we have a misclassified sample $x_i$, respectively $ - y_i \\langle x_i,w \\rangle \\leq 0 $, update the weight vector\n",
    "$w$ by moving it in the direction of the misclassified sample.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$w = w + y_i x_i$$\n",
    "\n",
    "With this update rule in mind, we can start writing our perceptron algorithm in python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Our Data Set \n",
    "\n",
    "First we need to define a labeled data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "    [-1, 2],\n",
    "    [3, 0],\n",
    "    [0, 4],\n",
    "    [1, 2],\n",
    "    [2, 2]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "Next we fold a bias term -1 into the data set. This is needed for the SGD to work. Details see [The Perceptron algorithm](https://www.google.de/url?sa=t&rct=j&q=&esrc=s&source=web&cd=3&ved=0ahUKEwiQvp-F_PjSAhVLWRoKHbyLCgEQFggrMAI&url=http%3A%2F%2Fu.cs.biu.ac.il%2F~jkeshet%2Fteaching%2Fiml2016%2Fiml2016_tirgul03.pdf&usg=AFQjCNFpAYxgitb3mOnpE4aQdu6iLgFc0g&bvm=bv.150729734,d.d2s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "    [-1,2,-1],\n",
    "    [3,0,-1],\n",
    "    [0,4,-1],\n",
    "    [1,5,-1],\n",
    "    [2,2,-1],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y = np.array([-1,-1,1,1,1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Lets Start Implementing Stochastic Gradient Descent \n",
    "\n",
    "Finally we can code our SGD algorithm using our update rule. To keep it simple, we will linearly loop over the sample set. For larger data sets it makes sence, to randomly pick a sample during each iteration in the for-loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def perceptron_sgd(X, Y):\n",
    "    w = np.zeros(len(X[0]))\n",
    "    eta = 1\n",
    "    epochs = 10\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for i, x in enumerate(X):\n",
    "            if (np.dot(X[i], w)*Y[i]) <= 0:\n",
    "                w = w + eta*X[i]*Y[i]\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Code Description Line By Line\n",
    "\n",
    "line <b>2</b>: Initialize the weight vector for the perceptron with zeros<br>\n",
    "line <b>3</b>: Set the learning rate to 1<br>\n",
    "line <b>4</b>: Set the number of epochs<br>\n",
    "line <b>7</b>: Iterate over each sample in the data set<br>\n",
    "line <b>8</b>: Misclassification condition $−y_i \\langle x_i,w \\rangle \\leq 0$\n",
    "line <b>9</b>: Update rule for the weights $w = w + y_i * x_i$ including the learning rate\n",
    "\n",
    "### Let The Perceptron Learn! \n",
    "\n",
    "Next we can execute our code and check, how many iterations are needed, until all sampels are classified right. To see the learning progress of the perceptron, we add a plotting feature to our algorithm, counting the total error in each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def perceptron_sgd_plot(X, Y):\n",
    "    '''\n",
    "    train perceptron and plot the total loss in each epoch.\n",
    "    \n",
    "    :param X: data samples\n",
    "    :param Y: data labels\n",
    "    :return: weight vector as a numpy array\n",
    "    '''\n",
    "    w = np.zeros(len(X[0]))\n",
    "    eta = 1\n",
    "    n = 10\n",
    "    errors = []\n",
    "\n",
    "    for t in range(n):\n",
    "        total_error = 0\n",
    "        for i, x in enumerate(X):\n",
    "            if (np.dot(X[i], w)*Y[i]) <= 0:\n",
    "                total_error += (np.dot(X[i], w)*Y[i])\n",
    "                w = w + eta*X[i]*Y[i]\n",
    "        errors.append(total_error*-1)\n",
    "        \n",
    "    plt.plot(errors)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Total Loss')\n",
    "    \n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  2.  4.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEPCAYAAABLIROyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2d22053d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(perceptron_sgd_plot(X,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "This means, that the perceptron needed five epochs to classify all samples right (total error is zero). The weight vector is $(1,2,4)$.<br>\n",
    "We can extract the following prediction function now:\n",
    "\n",
    "\n",
    "$$\n",
    "f(x) = \\langle x,(1,2)\\rangle - 4\n",
    "$$\n",
    "\n",
    "The weight vector is $(1,2)$ and the bias term is the third entry -4.\n",
    "\n",
    "Lets classify the samples in our data set by hand now:\n",
    "\n",
    "First sample $(-1, 2)$, supposed to be negative:\n",
    "\n",
    "$$-1*1+2*2 - 4 = sign(-1) = -1$$\n",
    "\n",
    "Second sample $(3, 0)$, supposed to be negative:\n",
    "\n",
    "$$3*1+0*2 - 4 = sign(-1) = -1$$\n",
    "\n",
    "Third sample $(0, 4)$, supposed to be positive:\n",
    "\n",
    "$$0*1+4*2-4 = sign(4) = +1$$\n",
    "\n",
    "Fourth sample $(1, 5)$, supposed to be positive:\n",
    "\n",
    "$$1*1+5*2 - 4 = sign(7) = +1$$\n",
    "\n",
    "Fifth sample $(2, 2)$, supposed to be positive:\n",
    "\n",
    "$$2*1+2*2 - 4 = sign(1) = +1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Final Thoughts \n",
    "\n",
    "Thats all about it. If you got so far, I hope you could learn something. Keep in mind, that the basic structure is the SGD and this is just four lines of code. It contains all the learning magic. Cool isnt it?\n",
    "\n",
    "I am looking forward for your comments.\n",
    "\n",
    "Greetings from Mavicc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
